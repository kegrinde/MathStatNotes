[["index.html", "Mathematical Statistics Welcome!", " Mathematical Statistics Kelsey Grinde Updated: 2021-01-19 Welcome! Welcome to the course notes for MATH/STAT 455: Mathematical Statistics at Macalester College. These notes were created by Kelsey Grinde and draw heavily from the course textbook: An Introduction to Mathematical Statistics and Its Applications by Richard Larsen and Morris Marx (6th Edition) I will be editing and adding to these notes throughout Spring 2021, so please check back for updates! If you find any typos or have other questions, please email kgrinde@macalester.edu. "],["probability-review.html", "1 Probability Review 1.1 Learning Goals 1.2 (Optional) Textbook Reading Guide", " 1 Probability Review This course builds on topics that you covered in MATH/STAT 354: Probability. Some of you might have taken Probability last semester, and for others it might have been awhile. I certainly don’t expect you to remember everything you learned in that class, but there are some concepts from Probability that we will use fairly often in this class (see the list below): if you’re rusty on any of these, I recommend spending some time reviewing. 1.1 Learning Goals Distinguish between important probability models (e.g., Normal, Binomial) Derive the expected value and variance of a single random variable or a sum of random variables Find the distribution of order statistics (e.g., minimum, maximum) Define the moment generating function and use it to find moments or identify pdfs 1.2 (Optional) Textbook Reading Guide Read: Chapters 2–4 (pages 15–277) Definitions: probability density function (discrete, continuous) cumulative distribution function (discrete, continuous) joint probability density function conditional probability density function independence random variable expected value variance \\(r^{th}\\) moment covariance random sample order statistic moment generating function Binomial distribution Poisson distribution Geometric distribution Negative Binomial distribution Normal/Gaussian distribution Gamma distribution Exponential distribution Uniform distribution Theorems: Law of Total Probability – Theorem 2.4.1 Bayes’ Theorem – Theorem 2.4.2 Relationship between pdf and cdf – Theorem 3.4.1 and Theorem 3.7.3 Expected value and variance of linear transformations of random variables – Corollary 3.5.1, Theorem 3.6.2, Theorem 3.9.2, Theorem 3.9.5 Relationship between mean and variance – Theorem 3.6.1 Finding a marginal pdf from a joint pdf – Theorem 3.7.1 and Theorem 3.7.2 Independence of random variables and joint pdfs – Theorem 3.7.4 Expected value of a product of independent random variables – Theorem 3.9.3 Covariance of independent random variables – Theorem 3.9.4 Finding the pdf and cdf of an order statistic – Theorem 3.10.1 Using MGFs to find moments – Theorem 3.12.1 Using MGFs to identify pdfs – Theorem 3.12.2 and Theorem 3.12.3 Central Limit Theorem – Theorem 4.3.2 Note: page and example numbers correspond to the 6th Edition of Larsen &amp; Marx and may not correspond directly to earlier editions of the textbook. "],["estimation.html", "2 Estimation 2.1 Learning Goals 2.2 Least Squares Estimation 2.3 Maximum Likelihood Estimation 2.4 The Method of Moments", " 2 Estimation In Probability, you calculated probabilities of events by assuming a probability model for data and then assuming you knew the value of the parameters in that model. Suppose that \\(X\\) and \\(Y\\) represent independent flips of a coin (0 = tails, 1 = heads) with probability \\(0.7\\) of landing heads. If you flip a coin two times, what’s the probabiity of observing a tail and then a head (\\(X = 0, Y = 1\\))? In Mathematical Statistics, we will similarly write down a probability model but then we will use observed data to estimate the value of the parameters in that model. Suppose we flipped a coin two times and observed one tail and then one head. Would you be more willing to believe that the probability of getting a head (\\(p\\)) is 0.7 or 0.4? If \\(p\\) could be anywhere between 0 and 1, what’s your best guess about what that value of \\(p\\) is based on the observed data? There is more than one technique that you can use to estimate the value of an unknown parameter. You’re already familiar with one technique—least squares estimation—from STAT 155. We’ll review the ideas behind that approach, as well as explore two other widely used estimation techniques: maximum likelihood estimation and the method of moments. 2.1 Learning Goals Understand the distinction between common parameter estimation methods (e.g., least squares, maximum likelihood, method of moments) Be able to implement common parameter estimation methods in a variety of settings and models 2.2 Least Squares Estimation 2.2.1 (Optional) Textbook Reading Guide Read: Sections 11.1 and 11.2, through the definition of residuals (pages 520–523), and Section 3.4 in the Stat 155 Notes Definitions: method of least squares residual predicted/fitted value Questions: What is the intuition behind least squares estimation? What are the typical steps to find a least squares estimate? How can we use least squares estimation to estimate the slope and intercept of a simple linear regression model? (work through Theorem 11.2.1 in detail and fill in any steps that the textbook left out) 2.2.2 In-Class Notes and Activities See Day 1 Slides and Activity 1 on Moodle. 2.3 Maximum Likelihood Estimation 2.3.1 Textbook Reading Guide Read: Section 5.1 and the first half of Section 5.2 (pages 278–288) Definitions: parameter statistic/estimator estimate likelihood function – Definition 5.2.1 maximum likelihood estimate – Definition 5.2.2 log-likelihood Note: wherever applicable, you should write down definitions for important vocab both “in words” and in mathematical notation. Questions: What is the intuition behind the maximum likelihood estimation (MLE) approach? What are the typical steps to find a MLE? (see Ex 5.2.1, 5.2.2, and Case Study 5.2.1; work through at least one of these examples in detail, filling in any steps that the textbook left out) Are there ever situations when the typical steps to finding a MLE don’t work? If so, what can we do instead to find the MLE? (see Ex 5.2.3, 5.2.4) How do the steps to finding a MLE change when we have more than one unknown parameter? (see Ex 5.2.5) 2.3.2 Videos MLE Intro (Day 2) MLE Example (Day 2) MLE Numerical Optimization (Day 3) 2.3.3 In-Class Notes and Activities MLE “by hand”: see Day 2 Slides and Activity 2 on Moodle. MLE by numerical techniques: see Day 3 Slides and Activity 3 on Moodle. 2.4 The Method of Moments 2.4.1 Textbook Reading Guide Read: the second half of Section 5.2 (pages 289–293) Definitions: theoretical moment sample moment method of moments estimates – Definition 5.2.3 Remember: wherever applicable, you should write down definitions for important vocab both “in words” and in mathematical notation. Questions: What is the intuition behind the method of moments (MOM) procedure for estimating unknown parameters? What are the typical steps to find a MOM estimator? (see Ex 5.2.6, 5.2.7, and Case Study 5.2.2; work through at least one of these examples in detail, filling in any steps that the textbook left out) What advantages does the MOM approach offer compared to MLE? Do the MOM and MLE approaches always yield the same estimate? (look through the examples in Section 5.2 and try using the other approach — do you always get the same answer?) 2.4.2 Videos MOM Intro MOM Example 2.4.3 In-Class Notes and Activities See Day 4 Slides and Activity 4 on Moodle. "],["properties-of-estimators.html", "3 Properties of Estimators 3.1 Learning Goals 3.2 Finite Sample Properties 3.3 Asymptotic Properties", " 3 Properties of Estimators Under Construction 3.1 Learning Goals Evaluate properties of different estimators (e.g., bias, efficiency, mean squared error, consistency) Understand the distinction between finite sample and asymptotic properties Use these properties to choose one type of estimator of another 3.2 Finite Sample Properties 3.2.1 Bias 3.2.2 Variance 3.2.3 MSE 3.3 Asymptotic Properties 3.3.1 Asymptotically Unbiased 3.3.2 Consistency 3.3.3 Asymptotic Normality "],["bayesian-statistics.html", "4 Bayesian Statistics 4.1 Learning Goals 4.2 Textbook Reading Guide", " 4 Bayesian Statistics Under Construction 4.1 Learning Goals Understand the difference between the Frequentist and Bayesian philosophies 4.2 Textbook Reading Guide "],["confidence-intervals.html", "5 Confidence Intervals 5.1 Learning Goals 5.2 Textbook Reading Guide", " 5 Confidence Intervals Under Construction 5.1 Learning Goals Understand the mathematical foundation of, be able to derive, be able to use, and be able to appropriately interpret confidence intervals 5.2 Textbook Reading Guide "],["hypothesis-testing.html", "6 Hypothesis Testing 6.1 Learning Goals 6.2 Textbook Reading Guide", " 6 Hypothesis Testing Under Construction 6.1 Learning Goals Understand the mathematical foundation of, be able to derive, and be able to use common hypothesis tests 6.2 Textbook Reading Guide "]]
