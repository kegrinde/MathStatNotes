[["index.html", "Mathematical Statistics Welcome!", " Mathematical Statistics Kelsey Grinde Updated: 2022-01-20 Welcome! Welcome to the course notes for MATH/STAT 455: Mathematical Statistics at Macalester College. These notes were created by Kelsey Grinde and draw heavily from the course textbook: An Introduction to Mathematical Statistics and Its Applications by Richard Larsen and Morris Marx (6th Edition) I will be editing and adding to these notes throughout Spring 2021, so please check back for updates! If you find any typos or have other questions, please email kgrinde@macalester.edu. "],["probability-review.html", "1 Probability Review Learning Goals (Optional) Textbook Reading Guide", " 1 Probability Review This course builds on topics that you covered in MATH/STAT 354: Probability. Some of you might have taken Probability last semester, and for others it might have been awhile. I certainly don’t expect you to remember everything you learned in that class, but there are some concepts from Probability that we will use fairly often in this class (see the list below): if you’re rusty on any of these, I recommend spending some time reviewing. Learning Goals Distinguish between important probability models (e.g., Normal, Binomial) Derive the expected value and variance of a single random variable or a sum of random variables Find the distribution of order statistics (e.g., minimum, maximum) Define the moment generating function and use it to find moments or identify pdfs (Optional) Textbook Reading Guide Read: Chapters 2–4 (pages 15–277) Definitions: probability density function (discrete, continuous) cumulative distribution function (discrete, continuous) joint probability density function conditional probability density function independence random variable expected value variance \\(r^{th}\\) moment covariance random sample order statistic moment generating function Binomial distribution Poisson distribution Geometric distribution Negative Binomial distribution Normal/Gaussian distribution Gamma distribution Exponential distribution Uniform distribution Theorems: Law of Total Probability – Theorem 2.4.1 Bayes’ Theorem – Theorem 2.4.2 Relationship between pdf and cdf – Theorem 3.4.1 and Theorem 3.7.3 Expected value and variance of linear transformations of random variables – Corollary 3.5.1, Theorem 3.6.2, Theorem 3.9.2, Theorem 3.9.5 Relationship between mean and variance – Theorem 3.6.1 Finding a marginal pdf from a joint pdf – Theorem 3.7.1 and Theorem 3.7.2 Independence of random variables and joint pdfs – Theorem 3.7.4 Expected value of a product of independent random variables – Theorem 3.9.3 Covariance of independent random variables – Theorem 3.9.4 Finding the pdf and cdf of an order statistic – Theorem 3.10.1 Using MGFs to find moments – Theorem 3.12.1 Using MGFs to identify pdfs – Theorem 3.12.2 and Theorem 3.12.3 Central Limit Theorem – Theorem 4.3.2 Note: page and example numbers correspond to the 6th Edition of Larsen &amp; Marx and may not correspond directly to earlier editions of the textbook. "],["estimation.html", "2 Estimation Learning Goals 2.1 Least Squares Estimation 2.2 Maximum Likelihood Estimation 2.3 The Method of Moments", " 2 Estimation In Probability, you calculated probabilities of events by assuming a probability model for data and then assuming you knew the value of the parameters in that model. Suppose that \\(X\\) and \\(Y\\) represent independent flips of a coin (0 = tails, 1 = heads) with probability \\(0.7\\) of landing heads. If you flip a coin two times, what’s the probabiity of observing a tail and then a head (\\(X = 0, Y = 1\\))? In Mathematical Statistics, we will similarly write down a probability model but then we will use observed data to estimate the value of the parameters in that model. Suppose we flipped a coin two times and observed one tail and then one head. Would you be more willing to believe that the probability of getting a head (\\(p\\)) is 0.7 or 0.4? If \\(p\\) could be anywhere between 0 and 1, what’s your best guess about what that value of \\(p\\) is based on the observed data? There is more than one technique that you can use to estimate the value of an unknown parameter. You’re already familiar with one technique—least squares estimation—from STAT 155. We’ll review the ideas behind that approach, as well as explore two other widely used estimation techniques: maximum likelihood estimation and the method of moments. Learning Goals Understand the distinction between common parameter estimation methods (e.g., least squares, maximum likelihood, method of moments) Be able to implement common parameter estimation methods in a variety of settings and models 2.1 Least Squares Estimation (Optional) Textbook Reading Guide Read: Sections 11.1 and 11.2, through the definition of residuals (pages 520–523), and Section 3.4 in the Stat 155 Notes Definitions: method of least squares residual predicted/fitted value Questions: What is the intuition behind least squares estimation? What are the typical steps to find a least squares estimate? How can we use least squares estimation to estimate the slope and intercept of a simple linear regression model? (work through Theorem 11.2.1 in detail and fill in any steps that the textbook left out) In-Class Notes and Activities See Day 1 Slides and Activity 1 on Moodle. 2.2 Maximum Likelihood Estimation Textbook Reading Guide Read: Section 5.1 and the first half of Section 5.2 (pages 278–288) Definitions: parameter statistic/estimator estimate likelihood function – Definition 5.2.1 maximum likelihood estimate – Definition 5.2.2 log-likelihood Note: wherever applicable, you should write down definitions for important vocab both “in words” and in mathematical notation. Questions: What is the intuition behind the maximum likelihood estimation (MLE) approach? What are the typical steps to find a MLE? (see Ex 5.2.1, 5.2.2, and Case Study 5.2.1; work through at least one of these examples in detail, filling in any steps that the textbook left out) Are there ever situations when the typical steps to finding a MLE don’t work? If so, what can we do instead to find the MLE? (see Ex 5.2.3, 5.2.4) How do the steps to finding a MLE change when we have more than one unknown parameter? (see Ex 5.2.5) Videos MLE Intro (Day 2) MLE Example (Day 2) MLE Numerical Optimization (Day 3) In-Class Notes and Activities MLE “by hand”: see Day 2 Slides and Activity 2 on Moodle. MLE by numerical techniques: see Day 3 Slides and Activity 3 on Moodle. 2.3 The Method of Moments Textbook Reading Guide Read: the second half of Section 5.2 (pages 289–293) Definitions: theoretical moment sample moment method of moments estimates – Definition 5.2.3 Remember: wherever applicable, you should write down definitions for important vocab both “in words” and in mathematical notation. Questions: What is the intuition behind the method of moments (MOM) procedure for estimating unknown parameters? What are the typical steps to find a MOM estimator? (see Ex 5.2.6, 5.2.7, and Case Study 5.2.2; work through at least one of these examples in detail, filling in any steps that the textbook left out) What advantages does the MOM approach offer compared to MLE? Do the MOM and MLE approaches always yield the same estimate? (look through the examples in Section 5.2 and try using the other approach — do you always get the same answer?) Videos MOM Intro MOM Example In-Class Notes and Activities See Day 4 Slides and Activity 4 on Moodle. "],["properties-of-estimators.html", "3 Properties of Estimators Learning Goals 3.1 Bias and Variance 3.2 Cramer-Rao Lower Bound 3.3 Consistency and Other Asymptotic Properties", " 3 Properties of Estimators As we’ve seen, there is more than one way to estimate an unknown parameter. Sometimes these different estimation techniques lead to the same estimator, but sometimes they do not. In that case, how can we choose which estimator to use? What makes one estimator “better” than another? Learning Goals Evaluate properties of different estimators (e.g., bias, efficiency, mean squared error, consistency) Understand the distinction between finite sample and asymptotic properties Use these properties to choose one type of estimator of another 3.1 Bias and Variance Textbook Reading Guide Read: Section 5.4 (pages 308–316) Definitions: unbiased asymptotically unbiased more efficient relative efficiency Questions: What is the difference between an estimator and an estimate? What are the properties of a “good” estimator? Intuitively, what is the difference between bias and precision? What are the typical steps to checking if an estimator is unbiased? (see Ex 5.4.2, 5.4.3, and 5.4.4) How can we construct an estimator that is unbiased? (see the Comment in Ex 5.4.2 and 5.4.4) If an estimator is unbiased, is it also asymptotically unbiased? If an estimator is asymptotically unbiased, is it necessarily unbiased? If we are comparing two estimators, how can we check which estimator is more efficient? (see Ex 5.4.5 and 5.4.6) Videos Bias and Variance Intro Bias Examples Variance Examples In-Class Notes and Activities See Day 5 Slides and Activity 5 on Moodle. 3.2 Cramer-Rao Lower Bound Textbook Reading Guide Read: Section 5.5 (pages 316–319) Definitions and Theorems: Cramer-Rao Inequality best or minimum-variance unbiased estimator efficient estimator efficiency of an unbiased estimator Questions: Can you describe, in your own words, what the Cramer-Rao Inequality tells us? What are the typical steps to deriving the Cramer-Rao lower bound (see Ex 5.5.1 and 5.5.2) What is the difference between a best and efficient estimator? Does one imply the other? (see the Comment below Definition 5.5.2) What steps do we need to take to show an estimator is efficient? What assumptions do we need to make in order for the Cramer-Rao Inequality to hold? Can you think of any examples of probability distributions that do not meet these assumptions? (see Ex 5.5.2) Videos CRLB Intro CRLB Example In-Class Notes and Activities See Day 6 Slides and Activity 6 on Moodle. 3.3 Consistency and Other Asymptotic Properties Textbook Reading Guide Read: Section 5.7 (pages 326–329) Definitions and Theorems: asymptotically unbiased consistent Chebyshev’s inequality weak law of large numbers Questions: What is the distinction between a fixed sample property and an asymptotic property of an estimator? Can you describe, in your own words, what it means for an estimator to be consistent? How can we use the \\(\\epsilon-\\delta\\) definition of consistency to show that an estimator is consistent? (see Ex 5.7.1) How can we use Chebyshev’s inequality to show that an estimator is consistent? (see Ex 5.7.2) Which of the estimation techniques that we’ve seen in this class yields consistent estimators? (see Comment after Ex 5.7.2) Videos Consistency Intro Consistency Examples In-Class Notes and Activities See Day 7 Slides and Activity 7 on Moodle. "],["bayesian-statistics.html", "4 Bayesian Statistics Learning Goals 4.1 Prior and Posterior Distributions 4.2 Bayes Estimators", " 4 Bayesian Statistics Bayesian estimation is an approach for incorporating prior knowledge into the estimation of unknown parameters. The Bayesian philosophy represents a total shift from the Frequentist philosophy that we’ve seen so far in this class, and that you’ve seen in your other stats classes. An important distinction between the two philosophies lies in their beliefs about unknown parameters. In particular: Frequentists believe that parameters are unknown but fixed constants Bayesians believe that parameters are random variables (so they have a probability distribution) Learning Goals Understand the difference between the Frequentist and Bayesian philosophies Derive the posterior distribution for an unknown parameter based on a specified prior and likelihood Derive the Bayes estimator for a given loss function Evaluate the properties of Bayes estimators Understand the impact of the choice of prior on Bayesian estimation 4.1 Prior and Posterior Distributions Textbook Reading Guide Read: first half of Section 5.8 (pages 329–337) Definitions and Theorems: Bayes’ Theorem prior distribution posterior distribution noninformative prior conjugate prior marginal pdf Questions: What is the difference between the Bayesian and Frequentist philosophies? What are the typical steps to deriving a posterior distribution? How is the posterior distribution impacted by the observed data and our choice of prior? What sorts of considerations should we keep in mind in choosing a prior? Videos Bayesian vs Frequentist Philosophy Prior and Posterior Distributions Intro Prior and Posterior Distributions Example In-Class Notes and Activities See Day 9 Slides and Activity 9 on Moodle. 4.2 Bayes Estimators Textbook Reading Guide Read: second half of Section 5.8 (pages 337–341) Definitions: posterior mode posterior median posterior mean loss function risk Bayes estimate Questions: Once we have a posterior distribution for \\(\\theta\\), how can we provide an estimate for \\(\\theta\\)? What are some examples of commonly-used loss functions? What are the typical steps to finding a Bayes estimate? What are the Bayes estimates for absolute error loss and squared error loss? How are the Bayes and maximum likelihood estimators typically related? What criteria do we consider in choosing an “optimal” estimator under the Bayesian paradigm? How do Bayes estimators stand up against Frequentist optimality criteria (e.g., bias, asymptotic bias, consistency)? Videos Bayesian Estimation Intro Bayesian Estimation Proofs Properties of Bayes Estimators In-Class Notes and Activities See Day 10 Slides and Activity 10 on Moodle. "],["confidence-intervals.html", "5 Confidence Intervals Learning Goals Textbook Reading Guide Videos In-Class Notes and Activities", " 5 Confidence Intervals So far in this class we have focused on the problem of estimating an unknown parameter. However, the estimators that we’ve derived thus far simply provide us with a “best guess” for an unknown parameter, without specifying anything about the uncertainty or precision of our estimate. One of the most widely used methods for providing a measure of uncertainty for an estimate is to construct a confidence interval. Confidence intervals provide a range of plausible values for an unknown parameter (i.e., values for the parameter that are consistent with our observed data), and their width provides an indication of our estimator’s precision. Confidence intervals are one of the most commonly misinterpreted tools in statistics. Understanding their mathematical foundations, and how they can be derived, provides insight into the ways we can (and cannot) interpret our confidence intervals. Learning Goals Understand the mathematical foundation and know how to appropriately interpret a confidence interval Derive a confidence interval for an unknown parameter using an exact pivot, approximate pivot, and/or the exact distribution of an estimator Use a confidence interval to choose a sample size Textbook Reading Guide Read First reading: review 4.3 (235–242) and read the first part of 5.3 (pages 293–298) Second reading: read the rest of 5.3 (pages 293–306) Definitions and Theorems First reading: Theorem 4.3.2 (Central Limit Theorem) Theorem 4.3.3 and its Corollaries 95% confidence interval 100(1-\\(\\alpha\\))% confidence interval Second reading: Theorem 4.3.1 margin of error sampling variation Theorem 5.3.2 Questions Consider these questions throughout both readings: What feature of a confidence interval tells us about the precision of our estimator? What does it mean to be 95% confident? How can we use simulations to assess the performance of confidence intervals? What are the typical steps to deriving a confidence interval? How can we interpret 95% confidence intervals? How can’t we interpret 95% confidence intervals? How can we use confidence intervals to choose a sample size for our study? Videos CI Intro (Day 11) CI via Pivots (Day 11) CI Pivot Examples (Day 11) CI via Exact Distributions (Day 12) In-Class Notes and Activities See Day 11–12 Slides and Activities 11–12 on Moodle. "],["hypothesis-testing.html", "6 Hypothesis Testing Learning Goals 6.1 Hypothesis Testing Framework 6.2 Likelihood Ratio Tests 6.3 Errors and Power", " 6 Hypothesis Testing Learning Goals Understand the mathematical foundation of and know how to correctly interpret the results of a hypothesis test Derive and implement a hypothesis test that can be used to distinguish between two conflicting hypotheses Understand the differences and relationships between type I error, type II error, and power, as well as the factors that influence each of them Calculate the power or type II error probability for a given hypothesis test 6.1 Hypothesis Testing Framework Textbook Reading Guide Read: Sections 6.1–6.3 (pages 343–359) Definitions: null hypothesis alternative hypothesis test statistic critical region critical value significance level statistically significant p-value Questions: What is the goal of hypothesis testing? What are the typical steps to deriving a hypothesis test? If we decide to reject \\(H_0\\), does that mean we’ve proved that \\(H_0\\) is false? How should we choose \\(\\alpha\\)? What is the difference between a one-sided and a two-sided alternative hypothesis? How does this impact our hypothesis testing procedure? How does this impact our p-value? What is the difference between saying that we “fail to reject \\(H_0\\)” and saying that we “accept \\(H_0\\)”? Which of these can we conclude, and which of these can’t we conclude? How are test statistics and p-values related? How can we conduct a hypothesis test for the Bernoulli/Binomial parameter \\(p\\) if we have a small sample size? Videos HT Intro HT Example In-Class Activities and Notes See Day 13 Slides and Activity 13 on Moodle. 6.2 Likelihood Ratio Tests Textbook Reading Guide Read: Section 6.5 (pages 375–378) Definitions: generalized likelihood ratio generalized likelihood ratio test Questions: What is the test statistic for a generalized likelihood ratio test? Why will the generalized likelihood ratio \\(\\lambda\\) be between 0 and 1? How do we typically find the critical value/region \\(\\lambda^*\\) for a generalized likelihood ratio test? Videos LRT Intro LRT Example In-Class Activities and Notes See Day 14 Slides and Activity 14 on Moodle. 6.3 Errors and Power Textbook Reading Guide Read: Section 6.4 (pages 359–373) Definitions: type I error type II error power Questions: How is type I error related to the choice of significance level? What are the typical steps to calculating the probability of a type II error? How is type II error related to the power of a hypothesis test? What factors influence the power of a test? In practice, which of these factors can we control? Videos Errors and Power Intro Errors and Power Example In-Class Activities and Notes See Day 15 Slides and Activity 15 on Moodle. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
